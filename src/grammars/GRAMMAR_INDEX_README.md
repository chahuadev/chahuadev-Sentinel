# Grammar Index System - Documentation

## üìã ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏£‡∏∞‡∏ö‡∏ö

‡∏£‡∏∞‡∏ö‡∏ö Grammar Index ‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ **Tokenizer** ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• grammar ‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢:
- ‡∏™‡πà‡∏á **language** (‡∏†‡∏≤‡∏©‡∏≤) ‡πÅ‡∏•‡∏∞ **type** (‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó) 
- ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏™‡πà‡∏á regex ‡∏´‡∏£‡∏∑‡∏≠ hardcode grammar
- ‡∏£‡∏±‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô JSON object
- ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏•‡∏Ç‡∏ê‡∏≤‡∏ô 2 ‡∏î‡πâ‡∏ß‡∏¢ Tokenizer ‡πÄ‡∏≠‡∏á

---

## üèóÔ∏è ‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏°

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Tokenizer  ‚îÇ ‡∏™‡πà‡∏á: language + type + itemName
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  index.js   ‚îÇ ‡∏ó‡∏≤‡∏á‡πÄ‡∏Ç‡πâ‡∏≤-‡∏ó‡∏≤‡∏á‡∏≠‡∏≠‡∏Å (Entry/Exit Point)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ grammar-index.js ‚îÇ ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏à‡∏≤‡∏Å grammar files
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ shared/grammars/*.json ‚îÇ Grammar data files
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Tokenizer  ‚îÇ ‡∏£‡∏±‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå ‚Üí ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏•‡∏Ç‡∏ê‡∏≤‡∏ô 2
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìÇ ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå

```
src/grammars/
‚îú‚îÄ‚îÄ index.js                          # Entry/Exit Point (‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏•‡∏à‡∏¥‡∏Å)
‚îú‚îÄ‚îÄ shared/
‚îÇ   ‚îú‚îÄ‚îÄ grammar-index.js              # Search Engine
‚îÇ   ‚îú‚îÄ‚îÄ grammar-index-examples.js     # ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
‚îÇ   ‚îî‚îÄ‚îÄ grammars/                     # Grammar Data Files
‚îÇ       ‚îú‚îÄ‚îÄ java.grammar.json
‚îÇ       ‚îú‚îÄ‚îÄ javascript.grammar.json
‚îÇ       ‚îú‚îÄ‚îÄ typescript.grammar.json
‚îÇ       ‚îî‚îÄ‚îÄ jsx.grammar.json
```

---

## üîç API Functions

### 1. **searchByType()** - ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ï‡∏≤‡∏° type (‡πÉ‡∏ä‡πâ‡∏ö‡πà‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î)

```javascript
import { searchByType } from './grammars/index.js';

const result = await searchByType('javascript', 'keyword', 'function');
```

**Parameters:**
- `language`: `'javascript' | 'typescript' | 'java' | 'jsx'`
- `type`: `'keyword' | 'operator' | 'punctuation' | 'literal' | ...`
- `itemName`: ‡∏ä‡∏∑‡πà‡∏≠ item ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤

**Returns:**
```javascript
{
  found: true,
  language: "javascript",
  type: "keyword",
  section: "keywords",
  item: "function",
  data: {
    type: "keyword",
    category: "declaration",
    description: "Function declaration keyword",
    // ... more fields
  },
  metadata: {
    number: 1,
    name: "keywords",
    title: "üìù Section 01: Keywords",
    // ... section info
  }
}
```

---

### 2. **batchSearch()** - ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô

```javascript
import { batchSearch } from './grammars/index.js';

const requests = [
  { type: 'keyword', itemName: 'function' },
  { type: 'operator', itemName: '=>' },
  { type: 'punctuation', itemName: '{' }
];

const results = await batchSearch('javascript', requests);
```

**Returns:** `Array<SearchResult>`

---

### 3. **identifyType()** - ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ item ‡πÄ‡∏õ‡πá‡∏ô type ‡∏≠‡∏∞‡πÑ‡∏£

```javascript
import { identifyType } from './grammars/index.js';

const result = await identifyType('javascript', 'function');
```

**Returns:**
```javascript
{
  found: true,
  language: "javascript",
  type: "keyword",        // ‚Üê ‡∏£‡∏∞‡∏ö‡∏∏‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô type ‡∏≠‡∏∞‡πÑ‡∏£
  section: "keywords",
  item: "function",
  data: { ... }
}
```

---

## üéØ Type Mapping

Grammar Index ‡πÅ‡∏õ‡∏•‡∏á `type` ‡πÄ‡∏õ‡πá‡∏ô `section name` ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥:

| Type               | Section Name        | ‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤              |
|--------------------|---------------------|-------------------------|
| `keyword`          | `keywords`          | All                     |
| `operator`         | `operators`         | JS, TS, Java            |
| `punctuation`      | `punctuation`       | All                     |
| `literal`          | `literals`          | All                     |
| `modifier`         | `modifiers`         | Java                    |
| `primitiveType`    | `primitiveTypes`    | Java                    |
| `annotation`       | `annotations`       | Java                    |
| `typeKeyword`      | `typeKeywords`      | TypeScript              |
| `typeOperator`     | `typeOperators`     | TypeScript              |
| `declaration`      | `declarations`      | TypeScript              |
| `moduleKeyword`    | `moduleKeywords`    | TypeScript              |
| `element`          | `elements`          | JSX                     |
| `expression`       | `expressions`       | JSX                     |
| `attribute`        | `attributes`        | JSX                     |
| `component`        | `builtInComponents` | JSX                     |

---

## üí° ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á

### Example 1: Tokenizer ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ keyword

```javascript
// Tokenizer ‡πÄ‡∏à‡∏≠ token "function"
const token = "function";
const language = "javascript";

// 1. ‡∏ñ‡∏≤‡∏° GrammarIndex
const result = await searchByType(language, 'keyword', token);

// 2. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
if (result.found) {
  console.log(`Token "${token}" is a ${result.type}`);
  console.log('Data:', result.data);
  
  // 3. Tokenizer ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏•‡∏Ç‡∏ê‡∏≤‡∏ô 2
  const binaryCode = convertToBinary(result.data);
  return binaryCode;
}
```

### Example 2: ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ TypeScript type operators

```javascript
const result = await searchByType('typescript', 'typeOperator', 'keyof');

if (result.found) {
  console.log('Found:', result.item);
  console.log('Description:', result.data.description);
  console.log('Section:', result.metadata.title);
}
```

### Example 3: ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏´‡∏•‡∏≤‡∏¢ tokens ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô

```javascript
const tokens = ['function', 'const', 'let', 'var'];
const requests = tokens.map(t => ({ type: 'keyword', itemName: t }));

const results = await batchSearch('javascript', requests);

results.forEach(r => {
  if (r.found) {
    console.log(`‚úÖ ${r.item}: ${r.data.category}`);
  }
});
```

---

## üîß ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Tokenizer

### ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Tokenizer ‡∏à‡∏£‡∏¥‡∏á

```javascript
import { PureBinaryTokenizer } from './grammars/shared/tokenizer-helper.js';
import { TokenizerBrainAdapter } from './grammars/shared/tokenizer-brain-adapter.js';

// 1. ‡∏™‡∏£‡πâ‡∏≤‡∏á Brain Adapter (‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏Å‡∏±‡∏ö GrammarIndex)
const brain = new TokenizerBrainAdapter('javascript');

// 2. ‡∏™‡∏£‡πâ‡∏≤‡∏á Tokenizer ‡∏û‡∏£‡πâ‡∏≠‡∏° Brain
const tokenizer = new PureBinaryTokenizer(brain);

// 3. Tokenize code
const code = 'const x = 5;';
const tokens = await tokenizer.tokenize(code);

// 4. ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
console.log(tokens);
// [
//   { type: 'KEYWORD', binary: 32, value: 'const', start: 0, end: 5 },
//   { type: 'IDENTIFIER', binary: 64, value: 'x', start: 6, end: 7 },
//   { type: 'OPERATOR', binary: 4, value: '=', start: 8, end: 9 },
//   { type: 'NUMBER', binary: 16, value: '5', start: 10, end: 11 },
//   { type: 'PUNCTUATION', binary: 8, value: ';', start: 11, end: 12 }
// ]
```

### ‡∏™‡∏•‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤

```javascript
const brain = new TokenizerBrainAdapter('javascript');
const tokenizer = new PureBinaryTokenizer(brain);

// Tokenize JavaScript
const jsTokens = await tokenizer.tokenize('function test() {}');

// ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô TypeScript
brain.setLanguage('typescript');
const tsTokens = await tokenizer.tokenize('interface User {}');

// ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô Java
brain.setLanguage('java');
const javaTokens = await tokenizer.tokenize('public class Main {}');
```

---

## ‚úÖ ‡∏Ç‡πâ‡∏≠‡∏î‡∏µ‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡πÉ‡∏´‡∏°‡πà

1. **‡πÑ‡∏°‡πà‡∏°‡∏µ Hardcode**
   - Grammar data ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå JSON
   - ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç grammar ‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ‡πÇ‡∏Ñ‡πâ‡∏î

2. **‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏£‡πá‡∏ß**
   - ‡πÉ‡∏ä‡πâ section-based search
   - O(1) lookup ‡πÉ‡∏ô section

3. **‡πÅ‡∏¢‡∏Å Responsibility ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô**
   - `index.js` = Entry/Exit Point
   - `grammar-index.js` = Search Engine
   - `Tokenizer` = Binary Conversion

4. **‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤**
   - JavaScript, TypeScript, Java, JSX
   - ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏†‡∏≤‡∏©‡∏≤‡πÉ‡∏´‡∏°‡πà‡πÑ‡∏î‡πâ‡∏á‡πà‡∏≤‡∏¢

5. **Section Metadata**
   - ‡∏£‡∏π‡πâ‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏≤‡∏à‡∏≤‡∏Å section ‡πÑ‡∏´‡∏ô
   - ‡∏°‡∏µ description, purpose, responsibility

---

## üöÄ ‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏†‡∏≤‡∏©‡∏≤‡πÉ‡∏´‡∏°‡πà

1. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå grammar: `shared/grammars/[language].grammar.json`
2. ‡πÄ‡∏û‡∏¥‡πà‡∏° section headers ‡∏ï‡∏≤‡∏° format ‡πÄ‡∏î‡∏¥‡∏°
3. ‡πÄ‡∏û‡∏¥‡πà‡∏° type mapping ‡πÉ‡∏ô `grammar-index.js` ‚Üí `_mapTypeToSection()`
4. Done! ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ‡πÇ‡∏Ñ‡πâ‡∏î‡∏≠‡∏∑‡πà‡∏ô

---

## üìù ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏

- ‡πÑ‡∏ü‡∏•‡πå grammar ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ section headers (__section_XX_name, etc.)
- Type ‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö section name ‡πÉ‡∏ô type mapping
- **Tokenizer** ‡πÉ‡∏ä‡πâ‡∏ú‡πà‡∏≤‡∏ô `TokenizerBrainAdapter` ‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏Å‡∏±‡∏ö GrammarIndex
- **Brain Adapter** ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å Tokenizer ‚Üí `searchByType()` / `loadGrammar()`
- Tokenizer ‡∏£‡∏±‡∏ö‡∏ú‡∏¥‡∏î‡∏ä‡∏≠‡∏ö‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏•‡∏Ç‡∏ê‡∏≤‡∏ô 2 ‡πÄ‡∏≠‡∏á (‡∏ó‡∏≥‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô tokenizer-helper.js ‡πÅ‡∏•‡πâ‡∏ß)

---

## üì¶ ‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö

### Core Files
- `index.js` - Entry/Exit Point (‡∏£‡∏±‡∏ö-‡∏™‡πà‡∏á‡∏ï‡πà‡∏≠)
- `shared/grammar-index.js` - Search Engine (‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ grammar)
- `shared/tokenizer-brain-adapter.js` - ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° Tokenizer ‚Üî GrammarIndex
- `shared/tokenizer-helper.js` - Pure Binary Tokenizer (‡πÅ‡∏õ‡∏•‡∏á String ‚Üí Binary)

### Data Files
- `shared/grammars/javascript.grammar.json`
- `shared/grammars/typescript.grammar.json`
- `shared/grammars/java.grammar.json`
- `shared/grammars/jsx.grammar.json`
- `shared/tokenizer-binary-config.json` (Tokenizer config)

### Examples
- `shared/grammar-index-examples.js` - ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ GrammarIndex
- `shared/tokenizer-examples.js` - ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Tokenizer

---

## üöÄ Quick Start

```bash
# 1. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö GrammarIndex
node src/grammars/shared/grammar-index-examples.js

# 2. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Tokenizer
node src/grammars/shared/tokenizer-examples.js
```

---

## üîó See Also

- `grammar-index-examples.js` - ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
- `shared/grammars/` - Grammar data files
- `index.js` - API entry points
